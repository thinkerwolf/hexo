---
title: 机器学习建议
date: 2019-05-28 11:42:03
categories:
- 机器学习
tags:
- machine-learning
---

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      <!--$表示行内元素，$$表示块状元素 -->
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js">
</script>

## 决定下一步做什么

### 调试学习算法

假设你已经实现了正则化的线性回归算法来预测房价。

但是，当你用一组新的数据测试预测函数时，你发现其预测会有很大的误差，下一步该怎么做。

- 获取更多的训练数据。
- 尝试更小的特性集合。
- 尝试获取更多特性。
- 尝试增加多项式特性。
- 尝试减小$\lambda$。
- 尝试增加$\lambda$。

上述方法可能有效，但是不是一个很系统的方法。特别是在实际生活中当使用第1个和第3个解决方法时，可能会相当耗时。所以需要一个系统性的诊断方法来判定。

### 机器学习诊断

一可以了解学习算法内部哪部分合适或者不合适的测试，并且可以获得建议来改进学习算法。

诊断发可能会花费一点时间，但绝对不会浪费时间。



## 评估预测

一个预测函数针对训练用例可能误差很小，但是仍然不正确（过拟合导致）。因此为了评估预测函数，并给定了一组训练用例，我们可以将数据分离成两部分：一组训练集合和一组测试集合。通常**训练集合**占总数据集合的70%，剩下的30%用作**测试集合**。

用这两个集合的新步骤如下：

1. 学习$\Theta$并使用训练集合最小化$J_{train}(\Theta)$。
2. 计算测试集合误差$J_{test}(\Theta)$

### 测试集合误差（代价）

#### 线性回归

$$
J_{test}(\Theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}{(h_\Theta(x_{test}^{(i)})-y_{test}^{(i)})^2}
$$

#### 分类误差

$$
err(h_\Theta(x),y)=1/0 \qquad if \; h_\Theta(x)\ge0.5 \,and \,y=0 \quad if \; h_\Theta(x)<0.5\,and\,y=1 
$$

这个给了我们基于一个误分类二进制0或1误差结果。测试集合的测试误差的平均值为：
$$
error=\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}{err(h_\Theta(x_{test}^{(i)}),y_{test}^{(i)})}
$$



## 模型选择和训练/验证/测试集合

一个学习算法与训练几个拟合地很好，并不代表它是个好的预测。它可能过拟合导致对测试集合的预测效果可能会非常差。训练数据集合在预测上的测量误差更小于在其他数据集上的误差更小。

给定多个多项式模型，我们可以使用一个系统的方式来定位最好的函数。为了选择预测的模型，你可以测试每个多项式等级来看看误差结果。

一种方式是将数据集分成三个部分：

- 训练集合train：60%
- 交叉验证集合cv：20%
- 测试集合：20%

现在我们可以用不同的集合计算出不同的误差值：

1. 每个等级的多项式采用**训练集合**优化$\Theta$参数。
2. 使用交**叉验证集合**寻找最小误差多项式等级d。
3. 使用**测试集合**评估泛化误差。$J_{test}(\Theta^{(d)})$。



## 诊断偏差/方差

这个章节我们测试多项式等级d和欠拟合或过拟合的关系。

- 我们得区分是偏差还是方差问题导致了差的预测效果。
- 高偏差是欠拟合，高方差是过拟合。我们需要在这两者之间找到适当的值。

训练误差会区域降低因为我们增加多项式等级。

同时，交叉验证误差将降低当我们将等级d增加到某个点，然后它会增加随着等级d的增加，形成一个凸的曲线。

**高偏差（欠拟合）**：$J_{train}(\Theta)$和$J_{CV}(\Theta)$都会很高，$J_{train}(\Theta)/approxJ_{CV}(\Theta)$。

**高方差(过拟合)**：$J_{train}(\Theta)$会低，$J_{CV}(\Theta)$会远比$J_{train}(\Theta)$大。

![](/images/machine/ml1.png)



## 正则化和偏差/方差

![](/images/machine/ml2.png)

从上面的图看出，当$\lambda$增加，我们的拟合变得更加坚平。从另一方面，随着$\lambda$逼近0，我们趋向过拟合。为了选择模型和正则化参数$\lambda$，需要以下步骤：

1. 创建lambda列表($\lambda\in\\{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24\\}$)
2. 创建一系列不同等级或变体的模型。
3. 遍历$\lambda$s并且针对每个$\lambda$检查所有模型来学习$\Theta$。
4. 在$J_{CV}(\Theta)$使用学习的$\Theta$计算交叉验证误差，**不带正则化**。
5. 选择交叉验证最小误差的最好组合。
6. 使用最好的$\Theta$组合和$\lambda$，将其应用到$J_{test}(\Theta)$来看看其泛化能力。



## 学习曲线

在只有几个数据点上训练算法基本会0误差。因为我们永远能找到一个二元方程与这些点完美契合。因此：

- 随着训练几个变大，二元方程误差随之增加
- 当达到一个特定m或训练集合数量，误差值会趋于平稳。

### 高偏差情况

低训练数量：导致$J_{train}(\Theta)$低，$J_{CV}(\Theta)$高。

高训练数量：导致$J_{train}(\Theta)$和$J_{CV}(\Theta)$都高。$J_{train}(\Theta)/approxJ_{CV}(\Theta)$

如果一个学习算法在高偏差情况，获取更多的训练样本不会有多大帮助。

![](/images/machine/ml3.png)

### 高方差情况

低训练数量：导致$J_{train}(\Theta)$低，$J_{CV}(\Theta)$高。

高训练数量：随着训练数量增加$J_{train}(\Theta)$增大，$J_{CV}(\Theta)$继续降低并不会区域平稳。并且$J_{train}(\Theta)<J_{CV}(\Theta)$但是两者之间的差继续有效。

如果学习算法有高方差问题，获得更多的训练数据似乎有帮助。

![](/images/machine/ml4.png)

## 决定下一步做什么（总结）

- 获得更多训练用例：修复高方差
- 尝试减少训练特性：修复高方差
- 添加特性：修复高偏差
- 添加多项式特性：修复高偏差
- 降低$\lambda$：修复高偏差
- 增高$\lambda$：修复高方差

### 诊断神经网络

- 少量参数的神经网络有欠拟合的倾向。计算方面更省力。
- 有大量参数的大型神经网络趋向过拟合。计算方面也更费力。这种情况可以使用正则化来处理过拟合。

使用单隐藏层是一个很好的开始。你可以使用交叉验证数据集验证不同的隐藏层数训练神经网络，选择表现最好的。

### 模型复杂度影响

- 低多项式有高偏差和低方法，这种情况，模型拟合始终很差。
- 高多项式极好地拟合训练数据但在测试数据比较差。对训练数量有低偏差，但高偏差很严重。
- 真实情况中，我们想选择一个泛化很好但同时很合理地拟合数据的模型。


















